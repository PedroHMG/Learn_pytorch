{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58596</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>22.21</td>\n",
       "      <td>6.5</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18164</th>\n",
       "      <td>Female</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not current</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44174</th>\n",
       "      <td>Male</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>30.70</td>\n",
       "      <td>6.1</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36760</th>\n",
       "      <td>Male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>26.40</td>\n",
       "      <td>5.8</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>Female</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>26.90</td>\n",
       "      <td>6.0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87939</th>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>4.8</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38173</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>24.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90636</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>16.65</td>\n",
       "      <td>6.6</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>Female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>25.69</td>\n",
       "      <td>8.2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40517</th>\n",
       "      <td>Female</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>32.61</td>\n",
       "      <td>6.5</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi   \n",
       "58596  Female  21.0             0              0         No Info  22.21  \\\n",
       "18164  Female  41.0             0              0     not current  27.32   \n",
       "44174    Male  60.0             1              0         No Info  30.70   \n",
       "36760    Male  20.0             0              0           never  26.40   \n",
       "53937  Female  52.0             0              0           never  26.90   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "87939  Female  30.0             0              0           never  27.32   \n",
       "38173  Female  79.0             0              0           never  24.65   \n",
       "90636  Female  49.0             0              0         No Info  16.65   \n",
       "1793   Female  47.0             0              0           never  25.69   \n",
       "40517  Female  51.0             0              0           never  32.61   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "58596          6.5                   90         0  \n",
       "18164          6.1                  140         0  \n",
       "44174          6.1                  155         0  \n",
       "36760          5.8                   80         0  \n",
       "53937          6.0                  140         0  \n",
       "...            ...                  ...       ...  \n",
       "87939          4.8                  145         0  \n",
       "38173          4.0                   80         0  \n",
       "90636          6.6                  145         0  \n",
       "1793           8.2                  160         1  \n",
       "40517          6.5                  240         1  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"data\\FashionMNIST\\raw\\diabetes_prediction_dataset.csv\")\n",
    "data = data.sample(frac=1)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "gender_dict = {\"Male\": 0, \"Female\": 1, \"Other\": 2}\n",
    "smoking_dict = {\"No Info\": 0, \"never\": 1, \"current\": 2, \"former\": 3, \"ever\": 4, \"not current\": 5}\n",
    "data=data.replace({\"gender\": gender_dict, \"smoking_history\": smoking_dict})\n",
    "\n",
    "for columns in data:\n",
    "    print(is_numeric_dtype(data[columns]))\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  ,  21.  ,   0.  , ...,  22.21,   6.5 ,  90.  ],\n",
       "       [  1.  ,  41.  ,   0.  , ...,  27.32,   6.1 , 140.  ],\n",
       "       [  0.  ,  60.  ,   1.  , ...,  30.7 ,   6.1 , 155.  ],\n",
       "       ...,\n",
       "       [  1.  ,  49.  ,   0.  , ...,  16.65,   6.6 , 145.  ],\n",
       "       [  1.  ,  47.  ,   0.  , ...,  25.69,   8.2 , 160.  ],\n",
       "       [  1.  ,  51.  ,   0.  , ...,  32.61,   6.5 , 240.  ]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=[\"diabetes\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DiabetesDataset object at 0x0000020E0EFBBD10>\n"
     ]
    }
   ],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, target_transform=None):\n",
    "        self.data = torch.tensor(data.drop(columns=[\"diabetes\"]).values, dtype=torch.float32)\n",
    "        self.label = torch.tensor(data[\"diabetes\"].values, dtype=torch.int32)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.data[idx], self.label[idx]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "train_data, test_data = np.split(data, [int(0.8*len(data))])\n",
    "\n",
    "train_dataset = DiabetesDataset(data=train_data)\n",
    "test_dataset = DiabetesDataset(data=test_data)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "print(test_dataloader.dataset.shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               acc_fn,\n",
    "               device=\"cuda\"):\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += acc_fn(y_pred, y)\n",
    "\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\n",
    "        \"model_name\": model.__class__.__name__,\n",
    "        \"model_loss\": loss.item(),\n",
    "        \"model_acc\": acc.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               acc_fn: torch.nn.Module,\n",
    "               device: torch.device = \"cuda\"):\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += acc_fn(y_pred.argmax(dim=1), y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {100 * train_acc:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              acc_fn,\n",
    "              device: torch.device = \"cuda\"):\n",
    "\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            test_pred = model(X)\n",
    "\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "\n",
    "            test_acc += acc_fn(test_pred.argmax(dim=1), y)\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"Test loss: {test_loss:.4f}, Test acc: {100 * test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class DiabetesModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_block = nn.Sequential(\n",
    "            nn.Linear(in_features=input_shape,\n",
    "                      out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units,\n",
    "                      out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_0 = DiabetesModelV0(input_shape=9, hidden_units=16, output_shape=1).to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)\n",
    "acc_fn = Accuracy(task=\"binary\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x8 and 9x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[259], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[1;32m----> 4\u001b[0m     train_step(model\u001b[39m=\u001b[39;49mmodel_0,\n\u001b[0;32m      5\u001b[0m                data_loader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[0;32m      6\u001b[0m                loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[0;32m      7\u001b[0m                optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m      8\u001b[0m                acc_fn\u001b[39m=\u001b[39;49macc_fn,\n\u001b[0;32m      9\u001b[0m                device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     10\u001b[0m     test_step(model\u001b[39m=\u001b[39mmodel_0,\n\u001b[0;32m     11\u001b[0m                data_loader\u001b[39m=\u001b[39mtest_dataloader,\n\u001b[0;32m     12\u001b[0m                loss_fn\u001b[39m=\u001b[39mloss_fn,\n\u001b[0;32m     13\u001b[0m                acc_fn\u001b[39m=\u001b[39macc_fn,\n\u001b[0;32m     14\u001b[0m                device\u001b[39m=\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[255], line 14\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, data_loader, loss_fn, optimizer, acc_fn, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_loader):\n\u001b[0;32m     12\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 14\u001b[0m     y_pred \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     16\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(y_pred, y)\n\u001b[0;32m     17\u001b[0m     train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "File \u001b[1;32mc:\\Users\\goesp\\Vs_codes\\Learn_pytorch\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[257], line 17\u001b[0m, in \u001b[0;36mDiabetesModelV0.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 17\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer_block(x)\n",
      "File \u001b[1;32mc:\\Users\\goesp\\Vs_codes\\Learn_pytorch\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\goesp\\Vs_codes\\Learn_pytorch\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\goesp\\Vs_codes\\Learn_pytorch\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\goesp\\Vs_codes\\Learn_pytorch\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x8 and 9x16)"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_step(model=model_0,\n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               acc_fn=acc_fn,\n",
    "               device=device)\n",
    "    test_step(model=model_0,\n",
    "               data_loader=test_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               acc_fn=acc_fn,\n",
    "               device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
